{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import json \n",
    "import csv\n",
    "import uuid\n",
    "import time\n",
    "from dateutil import parser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/boulder_flood_geolocated_tweets.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"created_at\", \"text\", \"coordinates\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['coordinates'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lat = []\n",
    "for i in data[\"coordinates\"]:\n",
    "    long_lat.append(list(i[\"coordinates\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"coordinates\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, 'coordinates', long_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(hosts=\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\" : {\"type\": \"text\", \"fielddata\": True},\n",
    "            \"created_at\" : {\"type\":\"date\"},\n",
    "            \"coordinates\": {\"type\": \"geo_shape\"}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(index=\"tweets_index\", body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'tweets_index'\n",
    "\n",
    "# Set the sleep duration in seconds\n",
    "sleep_duration = 1\n",
    "\n",
    "for _,row in data.iterrows():\n",
    "    # Create the bulk insertion data\n",
    "    bulk_data = [\n",
    "        {\n",
    "            '_index': index_name,\n",
    "            '_id': uuid.uuid4().int,   # unique id for the document\n",
    "            '_source': row.to_dict()  # convert the row to a dictionary and use it as the source data\n",
    "        }\n",
    "        for i in range(100)\n",
    "    ]\n",
    "\n",
    "# Iterate through the bulk data and perform the insertion\n",
    "for data in bulk_data:\n",
    "    client.create(index=index_name, id=data['_id'], body=data['_source'])\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query(text, distance = None, corrs= None, sdate=None, edate=None):\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\":\n",
    "                [\n",
    "                    {\n",
    "                        \"exists\": {\n",
    "                            \"field\": \"coordinates\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"fuzzy\":{\n",
    "                            \"text\": text\n",
    "\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                      \"geo_distance\": {\n",
    "                        \"distance\": distance,\n",
    "                        \"coordinates\": corrs\n",
    "                           \n",
    "                      }\n",
    "                    },\n",
    "                    {\n",
    "                        \"range\":{\n",
    "                            \"created_at\":{\n",
    "                                \"gte\": sdate,\n",
    "                                \"lte\": edate\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(text, distance, corrs, sdate, edate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = make_query(\"Flood\",  \"200km\", [-105.3375,  40.6112] , \"2013-01-01\", \"2014-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_res(query):\n",
    "# Perform a search using the client and the provided query\n",
    "    search = client.search(index=index_name, body=query)\n",
    "    # Initialize an empty list to store the search results\n",
    "    data = []\n",
    "    # Iterate over the search hits\n",
    "    for i in range(len(search[\"hits\"][\"hits\"])):\n",
    "        # Create a dictionary to store the search result\n",
    "        if search[\"hits\"][\"hits\"][i][\"_source\"][\"coordinates\"] == None: \n",
    "            continue\n",
    "        else:\n",
    "            doc = {\n",
    "                \"score\":search[\"hits\"][\"hits\"][i][\"_score\"],\n",
    "                # \"date\":search[\"hits\"][\"hits\"][i][\"_source\"][\"created_at\"],\n",
    "                # \"text\": search[\"hits\"][\"hits\"][i][\"_source\"][\"text\"],\n",
    "                \"lat\": search[\"hits\"][\"hits\"][i][\"_source\"][\"coordinates\"][0],\n",
    "                \"lng\": search[\"hits\"][\"hits\"][i][\"_source\"][\"coordinates\"][1]\n",
    "            }\n",
    "        # Add the dictionary to the list of search results\n",
    "        data.append(doc)\n",
    "    # Return the list of search results\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_res(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa809143aa61e2611f5215ff49d4d1a8c2e27f55540515136c2927f232afb4d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
